# -*- coding: utf-8 -*-
"""Copy of soft_computing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rlMpPrzKG4_41sqWKNy-4eA_aXO6x56l
"""

import pandas as pd
import numpy as np
import seaborn as sns
import random
import matplotlib.pyplot as plt
from sklearn import preprocessing
preprocessing.LabelEncoder()
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, accuracy_score, roc_curve, auc , roc_auc_score
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
import warnings
warnings.filterwarnings("ignore")

#load dataset
df = pd.read_csv('/content/breast-cancer.csv')

#Visualizate frist columns
df.head()

#droping rows of duplicate id
df = df.drop_duplicates('id', keep='last')

df.diagnosis.unique()

df.shape

df.info()

# Checking for missing values
df.isnull().sum()

#Making the replacement of the categorical variables
df['diagnosis']= df['diagnosis'].map({'M':0, 'B': 1})

df.head()

df=df.dropna(axis=1)

X=df.drop('diagnosis', axis=1)
y=df['diagnosis']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state = 10)

# scaling data
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

X_train.shape

knn_model = KNeighborsClassifier(n_neighbors=3)
knn_model.fit(X_train, y_train)

y_pred = knn_model.predict(X_test)

knn_class_rep = classification_report(y_test, y_pred)
accuracy = accuracy_score(y_test, y_pred)
print(accuracy)
print(knn_class_rep)

cm = confusion_matrix(y_test, y_pred)

plt.figure(figsize=(10, 6))


sns.heatmap(
    cm, annot=True, fmt='d', cmap= 'Blues', linewidths=0.4, square=True, cbar=True,
    xticklabels=["N", "Y"],
    yticklabels=["N", "Y"]
)

plt.xlabel('Predicted', fontsize=14, fontweight='bold')
plt.ylabel('Actual', fontsize=14, fontweight='bold')
plt.title('Confusion Matrix', fontsize=16, fontweight='bold')
plt.yticks(rotation=360)

plt.show()

columnsName=df.drop(labels= 'diagnosis', axis= 1).columns.values.tolist()

print(columnsName)

def accuracy(x):
  X = df[x]
  X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.30)
  model = KNeighborsClassifier()
  model.fit(X_train, y_train)
  acc= model.score(X_test, y_test)
  print("acc = ",acc)
  return acc

columnsName1=[0,1]
chromosomes=[]
for i in range(10):
  chro1=[]
  for i in range(31):
    item = random.choice(tuple(columnsName1))
    chro1.append(item)
  chromosomes.append(chro1)

def data(chromosomes1):
  chromosomes2=[]
  for i in range(len(chromosomes1)):
    if chromosomes1[i]==1:
      chromosomes2.append(columnsName[i])
  return chromosomes2

pb = []
def checkpersonalnest():
  for i in range(len(chromosomes)):
    pb.append(accuracy(data(chromosomes[i])))
checkpersonalnest()

def checkvelocity(globalbest):
    velocity=[]
    for j in range(len(chromosomes)):
        velocity.append(list(0+1*(np.random.random(1)[0])*(np.array(chromosomes[j])-np.array(chromosomes[j]))+1*(np.random.random(1)[0])*(np.array(globalbest)-np.array(chromosomes[j]))))
    #print(velocity)
    return velocity

def addingchromosomes(velocity):
    chromosomes2=[]
    for i in range(len(velocity)):
        nextchromo=[]
        for j in range(len(velocity[i])):
            nextchromo.append(chromosomes[i][j]+velocity[i][j])
        chromosomes2.append(nextchromo)
    return chromosomes2

def normalize(chromosomes2):
  for l in range(len(chromosomes2)):
    for m in range(len(chromosomes2[l])):
      if chromosomes2[l][m]>0.5:
        chromosomes2[l][m]=1
      else:
        chromosomes2[l][m]=0
  return chromosomes2

def checkpd(chromosomes2):
  personal=[]
  for i in range(len(chromosomes2)):
    personal.append(accuracy(data(chromosomes2[i])))
    for j in range(len(personal)):
      if(personal[j]>pb[j]):
        chromosomes[j]=chromosomes2[j]
        pb[j]=personal[j]
  return personal

max(pb)
ind = pb.index(max(pb))
globalbest=chromosomes[ind]
for i in range(20):
    chromosomes2=[]
    personal=[]
    velocity=checkvelocity(globalbest)
    chromosomes2=addingchromosomes(velocity)
    chromosomes2=normalize(chromosomes2)
    personal=checkpd(chromosomes2)
    globalbest=[]
    max(pb)
    ind = pb.index(max(pb))
    globalbest=chromosomes[ind]

max(pb)

ind = pb.index(max(pb))
print(ind)
globalbest=chromosomes[ind]

print(data(globalbest))

globalbest = data(globalbest)

x = df[globalbest]

x

X_train, X_test, y_train, y_test = train_test_split(x, y, test_size= 0.2, random_state = 10)

knn_model = KNeighborsClassifier(n_neighbors=3)
knn_model.fit(X_train, y_train)

y_pred = knn_model.predict(X_test)

knn_class_rep = classification_report(y_test, y_pred)
accuracy = accuracy_score(y_test, y_pred)
print(accuracy)
print(knn_class_rep)

from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score
import numpy as np

class PSO:
    def __init__(self, num_particles, max_iterations, dimension, X_train, X_test, y_train, y_test, model_class):
        self.num_particles = num_particles
        self.max_iterations = max_iterations
        self.dimension = dimension
        self.X_train, self.X_test, self.y_train, self.y_test = X_train, X_test, y_train, y_test
        self.model_class = model_class

        # Hyperparameters
        self.w = 0.5  # Inertia weight
        self.c1 = 2    # Cognitive coefficient
        self.c2 = 2    # Social coefficient

        # Initialize particles
        self.particles_position = np.random.uniform(low=1, high=20, size=(self.num_particles, self.dimension))
        self.particles_velocity = np.zeros((self.num_particles, self.dimension))
        self.pbest_position = self.particles_position  # Personal best position
        self.pbest_value = np.full(self.num_particles, -np.inf)  # Personal best value (maximization)
        self.gbest_position = None  # Global best position
        self.gbest_value = -np.inf  # Global best value (maximization)
        self.best_accuracy = -np.inf  # Best accuracy
        self.best_solution = None  # Best solution

    def optimize(self):
        for i in range(self.max_iterations):
            # Evaluate fitness for each particle
            for j in range(self.num_particles):
                accuracy = self._evaluate_accuracy(self.particles_position[j])

                # Update personal best
                if accuracy > self.pbest_value[j]:
                    self.pbest_value[j] = accuracy
                    self.pbest_position[j] = self.particles_position[j]

                # Update global best
                if accuracy > self.gbest_value:
                    self.gbest_value = accuracy
                    self.gbest_position = self.particles_position[j]
                    self.best_solution = self.gbest_position.copy()  # Store the best solution
                    self.best_accuracy = self.gbest_value  # Store the best accuracy

            # Update particle velocity and position
            for j in range(self.num_particles):
                r1 = np.random.rand(self.dimension)  # Random numbers
                r2 = np.random.rand(self.dimension)

                cognitive_component = self.c1 * r1 * (self.pbest_position[j] - self.particles_position[j])
                social_component = self.c2 * r2 * (self.gbest_position - self.particles_position[j])

                # Update velocity
                self.particles_velocity[j] = self.w * self.particles_velocity[j] + cognitive_component + social_component

                # Update position
                self.particles_position[j] = self.particles_position[j] + self.particles_velocity[j]

        return self.best_solution, self.best_accuracy

    def _evaluate_accuracy(self, position):
        # Assuming the first dimension represents the hyperparameter value (e.g., k for KNN)
        hyperparameter_value = int(position[0])
        if hyperparameter_value < 1:
            hyperparameter_value = 1  # Set a minimum value for the hyperparameter

        model = self.model_class(n_neighbors=hyperparameter_value)  # Instantiate model with the hyperparameter value
        model.fit(self.X_train, self.y_train)
        y_pred = model.predict(self.X_test)
        return accuracy_score(self.y_test, y_pred)

# Example usage
X = np.random.rand(100, 2)  # Sample data
y = np.random.randint(0, 2, 100)  # Sample labels
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)

pso = PSO(num_particles=100, max_iterations=200, dimension=1, X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test, model_class=KNeighborsClassifier)
best_solution, best_accuracy = pso.optimize()
print("Best solution (hyperparameter value):", best_solution)
print("Best accuracy:", best_accuracy)

from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score

def evaluate_knn_accuracy(X_train, X_test, y_train, y_test, k):
    knn = KNeighborsClassifier(n_neighbors=k)
    knn.fit(X_train, y_train)
    y_pred = knn.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    return accuracy

# Example usage
X = np.random.rand(100, 2)  # Sample data
y = np.random.randint(0, 2, 100)  # Sample labels
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)

k = 5  # Example hyperparameter value
accuracy = evaluate_knn_accuracy(X_train, X_test, y_train, y_test, k)
print("Accuracy:", accuracy)